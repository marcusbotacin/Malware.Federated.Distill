# Inspired by: https://mljar.com/blog/extract-rules-decision-tree/

import lief
import pandas as pd
from nfs.attribute_extractor import PEAttributeExtractor
import zipfile
import os, sys
from nfs.train_classifier import JSONAttributeExtractor, NeedForSpeedModel
from sklearn.ensemble import RandomForestClassifier
from skmultiflow.meta.adaptive_random_forests import AdaptiveRandomForest as ARFClassifier
import _pickle as cPickle
import gzip
import tempfile
import IPython
from pympler import asizeof
from sklearn import metrics
from sklearn import tree
from sklearn.tree import _tree
import humanize
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
import numpy as np
import warnings
warnings.filterwarnings('ignore')

def load_dataset(name):
	content = None
	with gzip.open(name, 'rb') as fp:
        	content = cPickle.load(fp)
	return content

def count_nodes(RF):
        nodes = 0
        for tree in RF.estimators_:
                nodes = nodes + tree.tree_.node_count
        return nodes

gw  = load_dataset("datasets/*.cpkl")
mw  = load_dataset("datasets/*.cpkl")
training = pd.DataFrame(mw + gw)

y_train = training['label']
del training['label']

clf = NeedForSpeedModel(classifier=RandomForestClassifier(n_estimators=1,random_state=0, n_jobs=-1))
training['label'] = y_train
clf.fit(training, n_features=2)

feature_names = []
for att in clf.TEXTUAL_ATTRIBUTES:
	f_names=[]
	for f_name in clf.textual_extractors[att].get_feature_names():
		f_names.append("%s::%s" % (att,f_name))
	feature_names+=f_names

#print(feature_names)
#x = tree.export_text(clf.classifier.estimators_[0], feature_names=feature_names)
#print(x)

def tree_to_code(tree, feature_names):
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]
    feature_names = [f.replace(" ", "_")[:-5] for f in feature_names]
    print("def predict({}):".format(", ".join(feature_names)))

    def recurse(node, depth):
        indent = "    " * depth
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            print("{}if {} <= {}:".format(indent, name, np.round(threshold,2)))
            recurse(tree_.children_left[node], depth + 1)
            print("{}else:  # if {} > {}".format(indent, name, np.round(threshold,2)))
            recurse(tree_.children_right[node], depth + 1)
        else:
            print("{}return {}".format(indent, tree_.value[node]))

    recurse(0, 1)

def get_rules(tree, feature_names, class_names):
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]

    paths = []
    path = []
    
    def recurse(node, path, paths):
        
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            p1, p2 = list(path), list(path)
            p1 += [f"({name} <= {np.round(threshold, 3)})"]
            recurse(tree_.children_left[node], p1, paths)
            p2 += [f"({name} > {np.round(threshold, 3)})"]
            recurse(tree_.children_right[node], p2, paths)
        else:
            path += [(tree_.value[node], tree_.n_node_samples[node])]
            paths += [path]
            
    recurse(0, path, paths)

    # sort by samples count
    samples_count = [p[-1][1] for p in paths]
    ii = list(np.argsort(samples_count))
    paths = [paths[i] for i in reversed(ii)]
    
    rules = []
    for path in paths:
        rule = "if "
        
        for p in path[:-1]:
            if rule != "if ":
                rule += " and "
            rule += str(p)
        rule += " then "
        if class_names is None:
            rule += "response: "+str(np.round(path[-1][0][0][0],3))
        else:
            classes = path[-1][0][0]
            l = np.argmax(classes)
            rule += f"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)"
        rule += f" | based on {path[-1][1]:,} samples"
        rules += [rule]
        
    return rules

def gen_yara(raw_rule, id=0):
	filename = os.path.join(sys.argv[1],"%d.yar" % id)
	f = open(filename,"w")
	print("import \"pe\"")
	f.write("import \"pe\"\n")
	print("rule rule_from_ml_%d {" % id)
	f.write("rule rule_from_ml_%d {\n" % id)
	print("\tcondition:")
	f.write("\tcondition:\n")
	libs = 0
	funcs = 0
	exports = 0
	dll_chars = 0
	chars=0
	for token in raw_rule.split(" "):
		if "libraries::" in token:
			if libs != 0 or funcs!=0 or exports!=0 or dll_chars != 0 or chars!=0:
				print("\t\tand")
				f.write("\t\tand\n")
			print("\t\tpe.imports(/%s/i,/(.)/i)" % token.split("::")[1])
			f.write("\t\tpe.imports(/%s/i,/(.)/i)\n" % token.split("::")[1])
			libs+=1
		if "functions::" in token:
			if libs !=0 or funcs != 0 or exports!=0 or dll_chars !=0 or chars!=0:
				print("\t\tand")
				f.write("\t\tand\n")
			print("\t\tpe.imports(/(.).dll/i, /%s/i)" % token.split("::")[1])
			f.write("\t\tpe.imports(/(.).dll/i, /%s/i)\n" % token.split("::")[1])
			funcs+=1
		if "exports_list::" in token:
			if libs != 0 or funcs!=0 or exports!=0 or dll_chars != 0 or chars!=0:
				print("\t\tand")
				f.write("\t\tand\n")
			token = token.replace("?","\?")
			print("\t\tpe.exports(/%s/i)" % token.split("::")[1])
			f.write("\t\tpe.exports(/%s/i)\n" % token.split("::")[1])
			exports+=1
		if "dll_characteristics_list" in token:
			if libs!=0 or funcs!=0 or exports!=0 or dll_chars !=0 or chars!=0:
				print("\t\tand")
				f.write("\t\tand\n")
			print("\t\tpe.dll_characteristics & pe.%s" % token.split("::")[1].upper())
			f.write("\t\tpe.dll_characteristics & pe.%s\n" % token.split("::")[1].upper())
			dll_chars+=1
		if "characteristics_list" in token and "dll" not in token:
			token = token.upper().replace("CHARA_32BIT_MACHINE","MACHINE_32BIT")
			if libs!=0 or funcs!=0 or exports!=0 or dll_chars !=0 or chars!=0:
				if libs !=0 or funcs != 0 or chars!=0:
					print("\t\tand")
					f.write("\t\tand\n")
			print("\t\tpe.characteristics & pe.%s" % token.split("::")[1].upper())
			f.write("\t\tpe.characteristics & pe.%s\n" % token.split("::")[1].upper())
			chars+=1
	print("}")
	f.write("}\n")
		
raw_rules = get_rules(clf.classifier.estimators_[0],feature_names,["goodware","malware"])

valid_rules = 0
for id, rule in enumerate(raw_rules):
	if "malware" in rule:
		gen_yara(rule,valid_rules)
		valid_rules+=1
